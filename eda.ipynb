{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "files = glob.glob(os.path.join(config.LABELS_PATH, \"*.tsv\"))\n",
    "for file_path in files:\n",
    "    path, file_name = os.path.split(file_path)\n",
    "    id, ext = os.path.splitext(file_name)\n",
    "    dfs[id] = pd.read_csv(file_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "\n",
    "def mask_image(image: cv2.Mat):\n",
    "    # mask using fillpoly\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    a = 300\n",
    "    b = 100\n",
    "    mask = cv2.fillPoly(\n",
    "        mask,\n",
    "        [\n",
    "            np.array([[a, 0], [b, image.shape[0]], [image.shape[1] - b, image.shape[0]], [image.shape[1] - a, 0],])\n",
    "        ],\n",
    "        255,\n",
    "    )\n",
    "    return cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "\n",
    "def get_pose_instance():\n",
    "    return mp_pose.Pose(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5,\n",
    "        model_complexity=0,\n",
    "        static_image_mode=False,\n",
    "        smooth_landmarks=False\n",
    "    )\n",
    "\n",
    "\n",
    "with get_pose_instance() as pose1, get_pose_instance() as pose2:\n",
    "    for id, df in dfs.items():\n",
    "        video_path = os.path.join(config.VIDEOS_PATH, f\"{id}.mp4\")\n",
    "        capture = cv2.VideoCapture(video_path)\n",
    "        for index, row in df.iterrows():\n",
    "            start_frame = row[\"start\"]\n",
    "            end_frame = row[\"end\"]\n",
    "            capture.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "            step = 1\n",
    "            for _ in range(start_frame, end_frame, step):\n",
    "                for _ in range(step):\n",
    "                    _, frame = capture.read()\n",
    "                # To improve performance, optionally mark the image as not writeable to\n",
    "                # pass by reference.\n",
    "                image = frame.copy()\n",
    "                image = mask_image(image)\n",
    "                image.flags.writeable = False\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                h, w = image.shape[:2]\n",
    "                image1 = image[: h // 2 + 20, 200 : w - 200]\n",
    "                results = pose1.process(image1)\n",
    "                image1.flags.writeable = True\n",
    "                image1 = cv2.cvtColor(image1, cv2.COLOR_RGB2BGR)\n",
    "                # mp_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image1,\n",
    "                    results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style(),\n",
    "                )\n",
    "\n",
    "                image2 = image[h // 2 - 120 :, 100 : w - 100]\n",
    "                results = pose2.process(image2)\n",
    "                image2.flags.writeable = True\n",
    "                image2 = cv2.cvtColor(image2, cv2.COLOR_RGB2BGR)\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image2,\n",
    "                    results.pose_landmarks,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style(),\n",
    "                )\n",
    "                \n",
    "                image[: h // 2 + 20, 200 : w - 200] = image1\n",
    "                image[h // 2 - 120 :, 100 : w - 100] = image2\n",
    "                cv2.imshow('result', image)\n",
    "\n",
    "                cv2.waitKey(1)\n",
    "        else:\n",
    "            cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80b057453a28bd7751b83d1dff7efd5d9c8ac1e2fbebc34701a458666e9568db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
